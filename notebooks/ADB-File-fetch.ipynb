{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOEFct-uNTDq"
   },
   "source": [
    "ELECTRICITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-14T15:17:56.055513Z",
     "iopub.status.busy": "2025-10-14T15:17:56.055323Z",
     "iopub.status.idle": "2025-10-14T15:17:56.264385Z",
     "shell.execute_reply": "2025-10-14T15:17:56.263444Z"
    },
    "executionInfo": {
     "elapsed": 8387,
     "status": "ok",
     "timestamp": 1747207905721,
     "user": {
      "displayName": "Aayush",
      "userId": "06063773002916323156"
     },
     "user_tz": -330
    },
    "id": "6c3inAIZ0E49",
    "outputId": "c1a038db-61aa-41b7-910d-d7cdd681bdb2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#  Google Colab ‑ single‑cell script\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#  Downloads the ADB electricity dataset, then\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#          └── processed/<indicator>_clean.csv – tidy (Economy,Year,Value)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m     21\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m, force_remount\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mglob\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtempfile\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mzipfile\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "#  Google Colab ‑ single‑cell script\n",
    "#  Downloads the ADB electricity dataset, then\n",
    "#    ①  builds ONE *merged* CSV (8 columns)\n",
    "#    ②  writes ONE folder / indicator with its own raw+clean CSVs\n",
    "#  Folder layout (everything overwritten on each run):\n",
    "#\n",
    "#  MyDrive/ADB/Global/Electricity\n",
    "#  ├── Merged_Indicators\n",
    "#  │   ├── raw/\n",
    "#  │   │   └── electricity_indicators_raw.<csv|xlsx>\n",
    "#  │   └── processed/\n",
    "#  │       └── electricity_indicators_merged_pivot.csv   <-- 8 cols\n",
    "#  └── Individual_Indicators\n",
    "#      └── <slug‑per‑indicator>/\n",
    "#          ├── raw/      (<indicator>_raw.csv   – wide, all years)\n",
    "#          └── processed/<indicator>_clean.csv – tidy (Economy,Year,Value)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import os, re, glob, io, tempfile, zipfile, requests, pandas as pd\n",
    "\n",
    "# ── CONFIG ────────────────────────────────────────────────\n",
    "URL  = \"https://kidb.adb.org/explore/download/c5feaa1a-c3c7-4d78-8aa7-52aeef9913a2\"\n",
    "ROOT = \"/content/drive/MyDrive/ADB/Global/Electricity\"\n",
    "\n",
    "MERGED_RAW_DIR  = os.path.join(ROOT, \"Merged_Indicators\", \"raw\")\n",
    "MERGED_PROC_DIR = os.path.join(ROOT, \"Merged_Indicators\", \"processed\")\n",
    "IND_ROOT        = os.path.join(ROOT, \"Individual_Indicators\")\n",
    "\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR, IND_ROOT):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# wipe merged folders so newest files always replace the old ones\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR):\n",
    "    for f in glob.glob(os.path.join(d, \"*\")):\n",
    "        try: os.remove(f)\n",
    "        except: pass\n",
    "\n",
    "def slugify(txt: str) -> str:\n",
    "    \"\"\"Safe folder/file name from indicator string.\"\"\"\n",
    "    return re.sub(r'[^\\w\\s-]', '', txt).strip().replace(\" \", \"_\")\n",
    "\n",
    "# ── 1. DOWNLOAD  ───────────────────────────────────────────\n",
    "resp = requests.get(URL, timeout=60)\n",
    "resp.raise_for_status()\n",
    "content = resp.content\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    if content[:2] == b\"PK\":                          # ZIP archive\n",
    "        zpath = os.path.join(tmp, \"data.zip\")\n",
    "        open(zpath, \"wb\").write(content)\n",
    "        with zipfile.ZipFile(zpath) as z:\n",
    "            member = next(n for n in z.namelist()\n",
    "                           if n.lower().endswith((\".csv\", \".xlsx\")))\n",
    "            raw_bytes = z.read(member)\n",
    "            ext = os.path.splitext(member)[1].lower()\n",
    "    else:                                             # single file\n",
    "        raw_bytes = content\n",
    "        ext = \".csv\" if b\",\" in content.splitlines()[0] else \".xlsx\"\n",
    "\n",
    "raw_merged_path = os.path.join(MERGED_RAW_DIR,\n",
    "                               f\"electricity_indicators_raw{ext}\")\n",
    "open(raw_merged_path, \"wb\").write(raw_bytes)\n",
    "\n",
    "# ── 2. LOAD RAW DATAFRAME ─────────────────────────────────\n",
    "read_fn = pd.read_csv if ext == \".csv\" else pd.read_excel\n",
    "df = read_fn(io.BytesIO(raw_bytes))\n",
    "\n",
    "df.columns = [c.strip().replace(\"\\n\", \" \") for c in df.columns]\n",
    "assert \"Indicator\" in df.columns and \"Economy\" in df.columns, \\\n",
    "    \"Expected columns 'Indicator' and 'Economy' not found!\"\n",
    "\n",
    "# ── 3. LONG → WIDE (8‑column merged table) ───────────────\n",
    "year_cols = [c for c in df.columns if re.fullmatch(r\"\\d{4}\", str(c))]\n",
    "long_df = (df\n",
    "           .melt(id_vars=[\"Indicator\", \"Economy\"],\n",
    "                 value_vars=year_cols,\n",
    "                 var_name=\"Year\",\n",
    "                 value_name=\"Value\")\n",
    "           .dropna(subset=[\"Value\"]))\n",
    "\n",
    "pivot_df = (long_df\n",
    "            .pivot_table(index=[\"Economy\", \"Year\"],\n",
    "                         columns=\"Indicator\",\n",
    "                         values=\"Value\",\n",
    "                         aggfunc=\"first\")\n",
    "            .reset_index())\n",
    "\n",
    "pivot_df.columns.name = None  # drop MultiIndex name\n",
    "\n",
    "# expected six indicators (adjust list if ADB adds more later)\n",
    "expected = [\n",
    "    \"Total Electricity Production (kWh billion)\",\n",
    "    \"Sources of Electricity, Combustible Fuels (% of total)\",\n",
    "    \"Sources of Electricity, Hydropower (% of total)\",\n",
    "    \"Sources of Electricity, Solar (% of total)\",\n",
    "    \"Sources of Electricity, Others (% of total)\",\n",
    "    \"Electric Power Consumption (kWh per capita)\",\n",
    "]\n",
    "\n",
    "# keep only those six, silently ignore any missing / extra cols\n",
    "cols_present = [c for c in expected if c in pivot_df.columns]\n",
    "pivot_df = pivot_df[[\"Economy\", \"Year\"] + cols_present]\n",
    "\n",
    "# save processed merged CSV\n",
    "processed_merged_path = os.path.join(\n",
    "    MERGED_PROC_DIR, \"electricity_indicators_merged_pivot.csv\"\n",
    ")\n",
    "pivot_df.to_csv(processed_merged_path, index=False)\n",
    "\n",
    "# ── 4. INDIVIDUAL INDICATOR FILES ─────────────────────────\n",
    "for ind_name, grp in df.groupby(\"Indicator\"):\n",
    "    slug = slugify(ind_name)\n",
    "\n",
    "    # create/clean folders\n",
    "    raw_dir  = os.path.join(IND_ROOT, slug, \"raw\")\n",
    "    proc_dir = os.path.join(IND_ROOT, slug, \"processed\")\n",
    "    os.makedirs(raw_dir,  exist_ok=True)\n",
    "    os.makedirs(proc_dir, exist_ok=True)\n",
    "    for p in glob.glob(os.path.join(raw_dir, \"*\")):  os.remove(p)\n",
    "    for p in glob.glob(os.path.join(proc_dir, \"*\")): os.remove(p)\n",
    "\n",
    "    # wide raw (all year columns)\n",
    "    grp.to_csv(os.path.join(raw_dir, f\"{slug}_raw.csv\"), index=False)\n",
    "\n",
    "    # tidy clean (Economy‑Year‑Value)\n",
    "    tidy = (long_df[long_df[\"Indicator\"] == ind_name]\n",
    "            .drop(columns=\"Indicator\"))\n",
    "    tidy.to_csv(os.path.join(proc_dir, f\"{slug}_clean.csv\"), index=False)\n",
    "\n",
    "# ── 5. SHOW SAMPLE ────────────────────────────────────────\n",
    "print(\"\\nSample of the merged 8‑column dataset:\")\n",
    "print(pivot_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rxt4fozts1ZM"
   },
   "source": [
    "ENERGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-14T15:17:56.300053Z",
     "iopub.status.busy": "2025-10-14T15:17:56.299845Z",
     "iopub.status.idle": "2025-10-14T15:17:56.381077Z",
     "shell.execute_reply": "2025-10-14T15:17:56.380255Z"
    },
    "executionInfo": {
     "elapsed": 15084,
     "status": "ok",
     "timestamp": 1747207827654,
     "user": {
      "displayName": "Aayush",
      "userId": "06063773002916323156"
     },
     "user_tz": -330
    },
    "id": "uVsnp3QAs07y",
    "outputId": "58290051-e743-4e2d-be3b-ccaaef2b52a7"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#  Google Colab single‑cell script   (ADB › Energy indicators)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      5\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m, force_remount\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mglob\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtempfile\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mzipfile\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "#  Google Colab single‑cell script   (ADB › Energy indicators)\n",
    "# -------------------------------------------------------------\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import os, re, glob, io, tempfile, zipfile, requests, pandas as pd\n",
    "\n",
    "# ── CONFIG ───────────────────────────────────────────────────\n",
    "URL  = \"https://kidb.adb.org/explore/download/4e61528b-8aec-4c49-951c-b36641766eeb\"\n",
    "ROOT = \"/content/drive/MyDrive/ADB/Global/Energy\"\n",
    "\n",
    "MERGED_RAW_DIR  = os.path.join(ROOT, \"Merged_Indicators\", \"raw\")\n",
    "MERGED_PROC_DIR = os.path.join(ROOT, \"Merged_Indicators\", \"processed\")\n",
    "IND_ROOT        = os.path.join(ROOT, \"Individual_Indicators\")\n",
    "\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR, IND_ROOT):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Wipe previous merged files so each run keeps only the latest pull\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR):\n",
    "    for f in glob.glob(os.path.join(d, \"*\")):\n",
    "        try: os.remove(f)\n",
    "        except: pass\n",
    "\n",
    "def slugify(txt: str) -> str:\n",
    "    return re.sub(r'[^\\w\\s-]', '', txt).strip().replace(\" \", \"_\")\n",
    "\n",
    "# ── 1. DOWNLOAD  ─────────────────────────────────────────────\n",
    "resp = requests.get(URL, timeout=60)\n",
    "resp.raise_for_status()\n",
    "content = resp.content\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    if content[:2] == b\"PK\":                               # ZIP archive\n",
    "        zpath = os.path.join(tmp, \"data.zip\"); open(zpath, \"wb\").write(content)\n",
    "        with zipfile.ZipFile(zpath) as z:\n",
    "            member = next(m for m in z.namelist() if m.lower().endswith((\".csv\", \".xlsx\")))\n",
    "            raw_bytes = z.read(member)\n",
    "            ext = os.path.splitext(member)[1].lower()\n",
    "    else:                                                  # single file\n",
    "        raw_bytes = content\n",
    "        ext = \".csv\" if b\",\" in content.splitlines()[0] else \".xlsx\"\n",
    "\n",
    "raw_merged_path = os.path.join(MERGED_RAW_DIR, f\"energy_indicators_raw{ext}\")\n",
    "open(raw_merged_path, \"wb\").write(raw_bytes)\n",
    "\n",
    "# ── 2. LOAD RAW DATAFRAME ───────────────────────────────────\n",
    "read_fn = pd.read_csv if ext == \".csv\" else pd.read_excel\n",
    "df = read_fn(io.BytesIO(raw_bytes))\n",
    "\n",
    "df.columns = [c.strip().replace(\"\\n\", \" \") for c in df.columns]\n",
    "assert {\"Indicator\", \"Economy\"}.issubset(df.columns), \"Columns 'Indicator' & 'Economy' required!\"\n",
    "\n",
    "# ── 3. LONG → WIDE MERGED TABLE (Economy, Year, indicators) ─\n",
    "year_cols = [c for c in df.columns if re.fullmatch(r\"\\d{4}\", str(c))]\n",
    "long_df = (df.melt(id_vars=[\"Indicator\", \"Economy\"],\n",
    "                   value_vars=year_cols,\n",
    "                   var_name=\"Year\",\n",
    "                   value_name=\"Value\")\n",
    "           .dropna(subset=[\"Value\"]))\n",
    "\n",
    "pivot_df = (long_df\n",
    "            .pivot_table(index=[\"Economy\", \"Year\"],\n",
    "                         columns=\"Indicator\",\n",
    "                         values=\"Value\",\n",
    "                         aggfunc=\"first\")\n",
    "            .reset_index())\n",
    "\n",
    "pivot_df.columns.name = None  # flatten\n",
    "\n",
    "# Save processed merged CSV\n",
    "proc_merged_path = os.path.join(MERGED_PROC_DIR,\n",
    "                                \"energy_indicators_merged_pivot.csv\")\n",
    "pivot_df.to_csv(proc_merged_path, index=False)\n",
    "\n",
    "# ── 4. INDIVIDUAL INDICATOR FILES ───────────────────────────\n",
    "for ind, grp in df.groupby(\"Indicator\"):\n",
    "    slug = slugify(ind)\n",
    "    raw_dir  = os.path.join(IND_ROOT, slug, \"raw\")\n",
    "    proc_dir = os.path.join(IND_ROOT, slug, \"processed\")\n",
    "    os.makedirs(raw_dir,  exist_ok=True)\n",
    "    os.makedirs(proc_dir, exist_ok=True)\n",
    "    # purge previous runs\n",
    "    for p in glob.glob(os.path.join(raw_dir, \"*\")):  os.remove(p)\n",
    "    for p in glob.glob(os.path.join(proc_dir, \"*\")): os.remove(p)\n",
    "\n",
    "    grp.to_csv(os.path.join(raw_dir, f\"{slug}_raw.csv\"), index=False)\n",
    "\n",
    "    tidy = (long_df[long_df[\"Indicator\"] == ind]\n",
    "            .drop(columns=\"Indicator\"))           # Economy, Year, Value\n",
    "    tidy.to_csv(os.path.join(proc_dir, f\"{slug}_clean.csv\"), index=False)\n",
    "\n",
    "# ── 5. SHOW SAMPLE ──────────────────────────────────────────\n",
    "print(\"\\nSample of merged Energy dataset (columns:\", len(pivot_df.columns), \")\")\n",
    "print(pivot_df.head())\n",
    "# -------------------------------------------------------------\n",
    "#  Google Colab single‑cell script   (ADB › Energy indicators)\n",
    "# -------------------------------------------------------------\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import os, re, glob, io, tempfile, zipfile, requests, pandas as pd\n",
    "\n",
    "# ── CONFIG ───────────────────────────────────────────────────\n",
    "URL  = \"https://kidb.adb.org/explore/download/4e61528b-8aec-4c49-951c-b36641766eeb\"\n",
    "ROOT = \"/content/drive/MyDrive/ADB/Global/Energy\"\n",
    "\n",
    "MERGED_RAW_DIR  = os.path.join(ROOT, \"Merged_Indicators\", \"raw\")\n",
    "MERGED_PROC_DIR = os.path.join(ROOT, \"Merged_Indicators\", \"processed\")\n",
    "IND_ROOT        = os.path.join(ROOT, \"Individual_Indicators\")\n",
    "\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR, IND_ROOT):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Wipe previous merged files so each run keeps only the latest pull\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR):\n",
    "    for f in glob.glob(os.path.join(d, \"*\")):\n",
    "        try: os.remove(f)\n",
    "        except: pass\n",
    "\n",
    "def slugify(txt: str) -> str:\n",
    "    return re.sub(r'[^\\w\\s-]', '', txt).strip().replace(\" \", \"_\")\n",
    "\n",
    "# ── 1. DOWNLOAD  ─────────────────────────────────────────────\n",
    "resp = requests.get(URL, timeout=60)\n",
    "resp.raise_for_status()\n",
    "content = resp.content\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    if content[:2] == b\"PK\":                               # ZIP archive\n",
    "        zpath = os.path.join(tmp, \"data.zip\"); open(zpath, \"wb\").write(content)\n",
    "        with zipfile.ZipFile(zpath) as z:\n",
    "            member = next(m for m in z.namelist() if m.lower().endswith((\".csv\", \".xlsx\")))\n",
    "            raw_bytes = z.read(member)\n",
    "            ext = os.path.splitext(member)[1].lower()\n",
    "    else:                                                  # single file\n",
    "        raw_bytes = content\n",
    "        ext = \".csv\" if b\",\" in content.splitlines()[0] else \".xlsx\"\n",
    "\n",
    "raw_merged_path = os.path.join(MERGED_RAW_DIR, f\"energy_indicators_raw{ext}\")\n",
    "open(raw_merged_path, \"wb\").write(raw_bytes)\n",
    "\n",
    "# ── 2. LOAD RAW DATAFRAME ───────────────────────────────────\n",
    "read_fn = pd.read_csv if ext == \".csv\" else pd.read_excel\n",
    "df = read_fn(io.BytesIO(raw_bytes))\n",
    "\n",
    "df.columns = [c.strip().replace(\"\\n\", \" \") for c in df.columns]\n",
    "assert {\"Indicator\", \"Economy\"}.issubset(df.columns), \"Columns 'Indicator' & 'Economy' required!\"\n",
    "\n",
    "# ── 3. LONG → WIDE MERGED TABLE (Economy, Year, indicators) ─\n",
    "year_cols = [c for c in df.columns if re.fullmatch(r\"\\d{4}\", str(c))]\n",
    "long_df = (df.melt(id_vars=[\"Indicator\", \"Economy\"],\n",
    "                   value_vars=year_cols,\n",
    "                   var_name=\"Year\",\n",
    "                   value_name=\"Value\")\n",
    "           .dropna(subset=[\"Value\"]))\n",
    "\n",
    "pivot_df = (long_df\n",
    "            .pivot_table(index=[\"Economy\", \"Year\"],\n",
    "                         columns=\"Indicator\",\n",
    "                         values=\"Value\",\n",
    "                         aggfunc=\"first\")\n",
    "            .reset_index())\n",
    "\n",
    "pivot_df.columns.name = None  # flatten\n",
    "\n",
    "# Save processed merged CSV\n",
    "proc_merged_path = os.path.join(MERGED_PROC_DIR,\n",
    "                                \"energy_indicators_merged_pivot.csv\")\n",
    "pivot_df.to_csv(proc_merged_path, index=False)\n",
    "\n",
    "# ── 4. INDIVIDUAL INDICATOR FILES ───────────────────────────\n",
    "for ind, grp in df.groupby(\"Indicator\"):\n",
    "    slug = slugify(ind)\n",
    "    raw_dir  = os.path.join(IND_ROOT, slug, \"raw\")\n",
    "    proc_dir = os.path.join(IND_ROOT, slug, \"processed\")\n",
    "    os.makedirs(raw_dir,  exist_ok=True)\n",
    "    os.makedirs(proc_dir, exist_ok=True)\n",
    "    # purge previous runs\n",
    "    for p in glob.glob(os.path.join(raw_dir, \"*\")):  os.remove(p)\n",
    "    for p in glob.glob(os.path.join(proc_dir, \"*\")): os.remove(p)\n",
    "\n",
    "    grp.to_csv(os.path.join(raw_dir, f\"{slug}_raw.csv\"), index=False)\n",
    "\n",
    "    tidy = (long_df[long_df[\"Indicator\"] == ind]\n",
    "            .drop(columns=\"Indicator\"))           # Economy, Year, Value\n",
    "    tidy.to_csv(os.path.join(proc_dir, f\"{slug}_clean.csv\"), index=False)\n",
    "\n",
    "# ── 5. SHOW SAMPLE ──────────────────────────────────────────\n",
    "print(\"\\nSample of merged Energy dataset (columns:\", len(pivot_df.columns), \")\")\n",
    "print(pivot_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M396AkGrPkIy"
   },
   "source": [
    "Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-14T15:17:56.383259Z",
     "iopub.status.busy": "2025-10-14T15:17:56.383009Z",
     "iopub.status.idle": "2025-10-14T15:17:56.419036Z",
     "shell.execute_reply": "2025-10-14T15:17:56.418148Z"
    },
    "executionInfo": {
     "elapsed": 9157,
     "status": "ok",
     "timestamp": 1747216948177,
     "user": {
      "displayName": "Aayush",
      "userId": "06063773002916323156"
     },
     "user_tz": -330
    },
    "id": "wJyIjauDPmWJ",
    "outputId": "fbff87f5-5143-40d5-ad74-c953c92acddb"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#  Google Colab single‑cell script   (ADB › Demographics)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      5\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m, force_remount\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mglob\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtempfile\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mzipfile\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "#  Google Colab single‑cell script   (ADB › Demographics)\n",
    "# -------------------------------------------------------------\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import os, re, glob, io, tempfile, zipfile, requests, pandas as pd\n",
    "\n",
    "# ── CONFIG ───────────────────────────────────────────────────\n",
    "URL  = \"https://kidb.adb.org/explore/download/415c4ae7-64e4-489d-abc3-1797a2febc46\"\n",
    "ROOT = \"/content/drive/MyDrive/ADB/Global/Demographics\"\n",
    "\n",
    "MERGED_RAW_DIR  = os.path.join(ROOT, \"Merged_Indicators\", \"raw\")\n",
    "MERGED_PROC_DIR = os.path.join(ROOT, \"Merged_Indicators\", \"processed\")\n",
    "IND_ROOT        = os.path.join(ROOT, \"Individual_Indicators\")\n",
    "\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR, IND_ROOT):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# wipe previous merged files so each run keeps only the latest pull\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR):\n",
    "    for f in glob.glob(os.path.join(d, \"*\")):\n",
    "        try: os.remove(f)\n",
    "        except: pass\n",
    "\n",
    "def slugify(txt: str) -> str:\n",
    "    return re.sub(r'[^\\w\\s-]', '', txt).strip().replace(\" \", \"_\")\n",
    "\n",
    "# ── 1. DOWNLOAD DATASET ─────────────────────────────────────\n",
    "resp = requests.get(URL, timeout=60)\n",
    "resp.raise_for_status()\n",
    "content = resp.content\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    if content[:2] == b\"PK\":                               # ZIP archive\n",
    "        zpath = os.path.join(tmp, \"data.zip\")\n",
    "        open(zpath, \"wb\").write(content)\n",
    "        with zipfile.ZipFile(zpath) as z:\n",
    "            member = next(m for m in z.namelist()\n",
    "                           if m.lower().endswith((\".csv\", \".xlsx\")))\n",
    "            raw_bytes = z.read(member)\n",
    "            ext = os.path.splitext(member)[1].lower()\n",
    "    else:                                                  # single file\n",
    "        raw_bytes = content\n",
    "        ext = \".csv\" if b\",\" in content.splitlines()[0] else \".xlsx\"\n",
    "\n",
    "raw_merged_path = os.path.join(MERGED_RAW_DIR,\n",
    "                               f\"demographics_indicators_raw{ext}\")\n",
    "open(raw_merged_path, \"wb\").write(raw_bytes)\n",
    "\n",
    "# ── 2. LOAD RAW DATAFRAME ───────────────────────────────────\n",
    "read_fn = pd.read_csv if ext == \".csv\" else pd.read_excel\n",
    "df = read_fn(io.BytesIO(raw_bytes))\n",
    "\n",
    "df.columns = [c.strip().replace(\"\\n\", \" \") for c in df.columns]\n",
    "assert {\"Indicator\", \"Economy\"}.issubset(df.columns), \\\n",
    "    \"Columns 'Indicator' & 'Economy' required!\"\n",
    "\n",
    "# ── 3. PIVOT TO MERGED TABLE  (Economy · Year · indicators) ─\n",
    "year_cols = [c for c in df.columns if re.fullmatch(r\"\\d{4}\", str(c))]\n",
    "long_df = (df.melt(id_vars=[\"Indicator\", \"Economy\"],\n",
    "                   value_vars=year_cols,\n",
    "                   var_name=\"Year\",\n",
    "                   value_name=\"Value\")\n",
    "           .dropna(subset=[\"Value\"]))\n",
    "\n",
    "pivot_df = (long_df\n",
    "            .pivot_table(index=[\"Economy\", \"Year\"],\n",
    "                         columns=\"Indicator\",\n",
    "                         values=\"Value\",\n",
    "                         aggfunc=\"first\")\n",
    "            .reset_index())\n",
    "\n",
    "pivot_df.columns.name = None  # flatten the header\n",
    "\n",
    "proc_merged_path = os.path.join(\n",
    "    MERGED_PROC_DIR, \"demographics_indicators_merged_pivot.csv\"\n",
    ")\n",
    "pivot_df.to_csv(proc_merged_path, index=False)\n",
    "\n",
    "# ── 4. SPLIT INTO INDIVIDUAL INDICATOR FOLDERS ─────────────\n",
    "for ind_name, grp in df.groupby(\"Indicator\"):\n",
    "    slug = slugify(ind_name)\n",
    "    raw_dir  = os.path.join(IND_ROOT, slug, \"raw\")\n",
    "    proc_dir = os.path.join(IND_ROOT, slug, \"processed\")\n",
    "    os.makedirs(raw_dir,  exist_ok=True)\n",
    "    os.makedirs(proc_dir, exist_ok=True)\n",
    "\n",
    "    # clear previous run\n",
    "    for p in glob.glob(os.path.join(raw_dir, \"*\")):  os.remove(p)\n",
    "    for p in glob.glob(os.path.join(proc_dir, \"*\")): os.remove(p)\n",
    "\n",
    "    # wide raw file (all year columns)\n",
    "    grp.to_csv(os.path.join(raw_dir, f\"{slug}_raw.csv\"), index=False)\n",
    "\n",
    "    # tidy clean file: Economy, Year, Value\n",
    "    tidy = (long_df[long_df[\"Indicator\"] == ind_name]\n",
    "            .drop(columns=\"Indicator\"))\n",
    "    tidy.to_csv(os.path.join(proc_dir, f\"{slug}_clean.csv\"), index=False)\n",
    "\n",
    "# ── 5. SHOW SAMPLE ──────────────────────────────────────────\n",
    "print(\"\\nSample of merged Demographics dataset (columns:\", len(pivot_df.columns), \")\")\n",
    "print(pivot_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPaC7JVTxmex4OWcglkKOM8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
