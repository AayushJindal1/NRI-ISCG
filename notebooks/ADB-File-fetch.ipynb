{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOEFct-uNTDq"
   },
   "source": [
    "ELECTRICITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-16T05:10:21.707292Z",
     "iopub.status.busy": "2025-05-16T05:10:21.700240Z",
     "iopub.status.idle": "2025-05-16T05:12:22.096989Z",
     "shell.execute_reply": "2025-05-16T05:12:22.096024Z"
    },
    "executionInfo": {
     "elapsed": 8387,
     "status": "ok",
     "timestamp": 1747207905721,
     "user": {
      "displayName": "Aayush",
      "userId": "06063773002916323156"
     },
     "user_tz": -330
    },
    "id": "6c3inAIZ0E49",
    "outputId": "c1a038db-61aa-41b7-910d-d7cdd681bdb2"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mount failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4bdceb8ce810>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         )\n\u001b[0;32m--> 279\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: mount failed"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "#  Google Colab ‑ single‑cell script\n",
    "#  Downloads the ADB electricity dataset, then\n",
    "#    ①  builds ONE *merged* CSV (8 columns)\n",
    "#    ②  writes ONE folder / indicator with its own raw+clean CSVs\n",
    "#  Folder layout (everything overwritten on each run):\n",
    "#\n",
    "#  MyDrive/ADB/Global/Electricity\n",
    "#  ├── Merged_Indicators\n",
    "#  │   ├── raw/\n",
    "#  │   │   └── electricity_indicators_raw.<csv|xlsx>\n",
    "#  │   └── processed/\n",
    "#  │       └── electricity_indicators_merged_pivot.csv   <-- 8 cols\n",
    "#  └── Individual_Indicators\n",
    "#      └── <slug‑per‑indicator>/\n",
    "#          ├── raw/      (<indicator>_raw.csv   – wide, all years)\n",
    "#          └── processed/<indicator>_clean.csv – tidy (Economy,Year,Value)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import os, re, glob, io, tempfile, zipfile, requests, pandas as pd\n",
    "\n",
    "# ── CONFIG ────────────────────────────────────────────────\n",
    "URL  = \"https://kidb.adb.org/explore/download/c5feaa1a-c3c7-4d78-8aa7-52aeef9913a2\"\n",
    "ROOT = \"/content/drive/MyDrive/ADB/Global/Electricity\"\n",
    "\n",
    "MERGED_RAW_DIR  = os.path.join(ROOT, \"Merged_Indicators\", \"raw\")\n",
    "MERGED_PROC_DIR = os.path.join(ROOT, \"Merged_Indicators\", \"processed\")\n",
    "IND_ROOT        = os.path.join(ROOT, \"Individual_Indicators\")\n",
    "\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR, IND_ROOT):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# wipe merged folders so newest files always replace the old ones\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR):\n",
    "    for f in glob.glob(os.path.join(d, \"*\")):\n",
    "        try: os.remove(f)\n",
    "        except: pass\n",
    "\n",
    "def slugify(txt: str) -> str:\n",
    "    \"\"\"Safe folder/file name from indicator string.\"\"\"\n",
    "    return re.sub(r'[^\\w\\s-]', '', txt).strip().replace(\" \", \"_\")\n",
    "\n",
    "# ── 1. DOWNLOAD  ───────────────────────────────────────────\n",
    "resp = requests.get(URL, timeout=60)\n",
    "resp.raise_for_status()\n",
    "content = resp.content\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    if content[:2] == b\"PK\":                          # ZIP archive\n",
    "        zpath = os.path.join(tmp, \"data.zip\")\n",
    "        open(zpath, \"wb\").write(content)\n",
    "        with zipfile.ZipFile(zpath) as z:\n",
    "            member = next(n for n in z.namelist()\n",
    "                           if n.lower().endswith((\".csv\", \".xlsx\")))\n",
    "            raw_bytes = z.read(member)\n",
    "            ext = os.path.splitext(member)[1].lower()\n",
    "    else:                                             # single file\n",
    "        raw_bytes = content\n",
    "        ext = \".csv\" if b\",\" in content.splitlines()[0] else \".xlsx\"\n",
    "\n",
    "raw_merged_path = os.path.join(MERGED_RAW_DIR,\n",
    "                               f\"electricity_indicators_raw{ext}\")\n",
    "open(raw_merged_path, \"wb\").write(raw_bytes)\n",
    "\n",
    "# ── 2. LOAD RAW DATAFRAME ─────────────────────────────────\n",
    "read_fn = pd.read_csv if ext == \".csv\" else pd.read_excel\n",
    "df = read_fn(io.BytesIO(raw_bytes))\n",
    "\n",
    "df.columns = [c.strip().replace(\"\\n\", \" \") for c in df.columns]\n",
    "assert \"Indicator\" in df.columns and \"Economy\" in df.columns, \\\n",
    "    \"Expected columns 'Indicator' and 'Economy' not found!\"\n",
    "\n",
    "# ── 3. LONG → WIDE (8‑column merged table) ───────────────\n",
    "year_cols = [c for c in df.columns if re.fullmatch(r\"\\d{4}\", str(c))]\n",
    "long_df = (df\n",
    "           .melt(id_vars=[\"Indicator\", \"Economy\"],\n",
    "                 value_vars=year_cols,\n",
    "                 var_name=\"Year\",\n",
    "                 value_name=\"Value\")\n",
    "           .dropna(subset=[\"Value\"]))\n",
    "\n",
    "pivot_df = (long_df\n",
    "            .pivot_table(index=[\"Economy\", \"Year\"],\n",
    "                         columns=\"Indicator\",\n",
    "                         values=\"Value\",\n",
    "                         aggfunc=\"first\")\n",
    "            .reset_index())\n",
    "\n",
    "pivot_df.columns.name = None  # drop MultiIndex name\n",
    "\n",
    "# expected six indicators (adjust list if ADB adds more later)\n",
    "expected = [\n",
    "    \"Total Electricity Production (kWh billion)\",\n",
    "    \"Sources of Electricity, Combustible Fuels (% of total)\",\n",
    "    \"Sources of Electricity, Hydropower (% of total)\",\n",
    "    \"Sources of Electricity, Solar (% of total)\",\n",
    "    \"Sources of Electricity, Others (% of total)\",\n",
    "    \"Electric Power Consumption (kWh per capita)\",\n",
    "]\n",
    "\n",
    "# keep only those six, silently ignore any missing / extra cols\n",
    "cols_present = [c for c in expected if c in pivot_df.columns]\n",
    "pivot_df = pivot_df[[\"Economy\", \"Year\"] + cols_present]\n",
    "\n",
    "# save processed merged CSV\n",
    "processed_merged_path = os.path.join(\n",
    "    MERGED_PROC_DIR, \"electricity_indicators_merged_pivot.csv\"\n",
    ")\n",
    "pivot_df.to_csv(processed_merged_path, index=False)\n",
    "\n",
    "# ── 4. INDIVIDUAL INDICATOR FILES ─────────────────────────\n",
    "for ind_name, grp in df.groupby(\"Indicator\"):\n",
    "    slug = slugify(ind_name)\n",
    "\n",
    "    # create/clean folders\n",
    "    raw_dir  = os.path.join(IND_ROOT, slug, \"raw\")\n",
    "    proc_dir = os.path.join(IND_ROOT, slug, \"processed\")\n",
    "    os.makedirs(raw_dir,  exist_ok=True)\n",
    "    os.makedirs(proc_dir, exist_ok=True)\n",
    "    for p in glob.glob(os.path.join(raw_dir, \"*\")):  os.remove(p)\n",
    "    for p in glob.glob(os.path.join(proc_dir, \"*\")): os.remove(p)\n",
    "\n",
    "    # wide raw (all year columns)\n",
    "    grp.to_csv(os.path.join(raw_dir, f\"{slug}_raw.csv\"), index=False)\n",
    "\n",
    "    # tidy clean (Economy‑Year‑Value)\n",
    "    tidy = (long_df[long_df[\"Indicator\"] == ind_name]\n",
    "            .drop(columns=\"Indicator\"))\n",
    "    tidy.to_csv(os.path.join(proc_dir, f\"{slug}_clean.csv\"), index=False)\n",
    "\n",
    "# ── 5. SHOW SAMPLE ────────────────────────────────────────\n",
    "print(\"\\nSample of the merged 8‑column dataset:\")\n",
    "print(pivot_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rxt4fozts1ZM"
   },
   "source": [
    "ENERGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-16T05:12:22.172037Z",
     "iopub.status.busy": "2025-05-16T05:12:22.171529Z",
     "iopub.status.idle": "2025-05-16T05:16:34.803077Z",
     "shell.execute_reply": "2025-05-16T05:16:34.802148Z"
    },
    "executionInfo": {
     "elapsed": 15084,
     "status": "ok",
     "timestamp": 1747207827654,
     "user": {
      "displayName": "Aayush",
      "userId": "06063773002916323156"
     },
     "user_tz": -330
    },
    "id": "uVsnp3QAs07y",
    "outputId": "58290051-e743-4e2d-be3b-ccaaef2b52a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of merged Energy dataset (columns: 18 )\n",
      "     Economy  Year Coal consumption Coal exports Coal imports Coal production  \\\n",
      "0  Australia  2015         55913344  392348681.2       125996     445761929.3   \n",
      "1  Australia  2016         59261030  389300203.7        31282     437041499.8   \n",
      "2  Australia  2017         61140641  378938582.9       103900     443001999.2   \n",
      "3  Australia  2018         62210989  381944255.6       228167     449938264.5   \n",
      "4  Australia  2019         60961575  393297916.1       181460     460453830.1   \n",
      "\n",
      "  Crude petroleum consumption Crude petroleum exports Crude petroleum imports  \\\n",
      "0                 30227667.91             13030995.38                20875382   \n",
      "1                 26410241.71             11946488.24             16976615.86   \n",
      "2                 25629597.78             11011318.16             17511063.72   \n",
      "3                 27075260.34             11209573.42             19256063.92   \n",
      "4                 26999317.38             12675735.37              18700162.5   \n",
      "\n",
      "  Crude petroleum production Electricity consumption Electricity exports  \\\n",
      "0                   16392460            252390834000                   0   \n",
      "1                   15819700            257428585000                   0   \n",
      "2                   13875240            258016971000                   0   \n",
      "3                   13293880            261056105000                   0   \n",
      "4                   15730260            264026746000                   0   \n",
      "\n",
      "  Electricity imports Electricity production Natural gas consumption  \\\n",
      "0                   0           252390834000             36473713000   \n",
      "1                   0           257428585000             37320572000   \n",
      "2                   0           258016971000             38261301000   \n",
      "3                   0           261056105000             39695014000   \n",
      "4                   0           264026746000             40324701000   \n",
      "\n",
      "  Natural gas exports Natural gas imports Natural gas production  \n",
      "0         34064464000          6373026000            68909400000  \n",
      "1         50118545920          7188593000            88200000000  \n",
      "2         70885372900          6556163000           105261000000  \n",
      "3         83899590000          5921114000           120256000000  \n",
      "4        101728836000          6411831000           145185106000  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "#  Google Colab single‑cell script   (ADB › Energy indicators)\n",
    "# -------------------------------------------------------------\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import os, re, glob, io, tempfile, zipfile, requests, pandas as pd\n",
    "\n",
    "# ── CONFIG ───────────────────────────────────────────────────\n",
    "URL  = \"https://kidb.adb.org/explore/download/4e61528b-8aec-4c49-951c-b36641766eeb\"\n",
    "ROOT = \"/content/drive/MyDrive/ADB/Global/Energy\"\n",
    "\n",
    "MERGED_RAW_DIR  = os.path.join(ROOT, \"Merged_Indicators\", \"raw\")\n",
    "MERGED_PROC_DIR = os.path.join(ROOT, \"Merged_Indicators\", \"processed\")\n",
    "IND_ROOT        = os.path.join(ROOT, \"Individual_Indicators\")\n",
    "\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR, IND_ROOT):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Wipe previous merged files so each run keeps only the latest pull\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR):\n",
    "    for f in glob.glob(os.path.join(d, \"*\")):\n",
    "        try: os.remove(f)\n",
    "        except: pass\n",
    "\n",
    "def slugify(txt: str) -> str:\n",
    "    return re.sub(r'[^\\w\\s-]', '', txt).strip().replace(\" \", \"_\")\n",
    "\n",
    "# ── 1. DOWNLOAD  ─────────────────────────────────────────────\n",
    "resp = requests.get(URL, timeout=60)\n",
    "resp.raise_for_status()\n",
    "content = resp.content\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    if content[:2] == b\"PK\":                               # ZIP archive\n",
    "        zpath = os.path.join(tmp, \"data.zip\"); open(zpath, \"wb\").write(content)\n",
    "        with zipfile.ZipFile(zpath) as z:\n",
    "            member = next(m for m in z.namelist() if m.lower().endswith((\".csv\", \".xlsx\")))\n",
    "            raw_bytes = z.read(member)\n",
    "            ext = os.path.splitext(member)[1].lower()\n",
    "    else:                                                  # single file\n",
    "        raw_bytes = content\n",
    "        ext = \".csv\" if b\",\" in content.splitlines()[0] else \".xlsx\"\n",
    "\n",
    "raw_merged_path = os.path.join(MERGED_RAW_DIR, f\"energy_indicators_raw{ext}\")\n",
    "open(raw_merged_path, \"wb\").write(raw_bytes)\n",
    "\n",
    "# ── 2. LOAD RAW DATAFRAME ───────────────────────────────────\n",
    "read_fn = pd.read_csv if ext == \".csv\" else pd.read_excel\n",
    "df = read_fn(io.BytesIO(raw_bytes))\n",
    "\n",
    "df.columns = [c.strip().replace(\"\\n\", \" \") for c in df.columns]\n",
    "assert {\"Indicator\", \"Economy\"}.issubset(df.columns), \"Columns 'Indicator' & 'Economy' required!\"\n",
    "\n",
    "# ── 3. LONG → WIDE MERGED TABLE (Economy, Year, indicators) ─\n",
    "year_cols = [c for c in df.columns if re.fullmatch(r\"\\d{4}\", str(c))]\n",
    "long_df = (df.melt(id_vars=[\"Indicator\", \"Economy\"],\n",
    "                   value_vars=year_cols,\n",
    "                   var_name=\"Year\",\n",
    "                   value_name=\"Value\")\n",
    "           .dropna(subset=[\"Value\"]))\n",
    "\n",
    "pivot_df = (long_df\n",
    "            .pivot_table(index=[\"Economy\", \"Year\"],\n",
    "                         columns=\"Indicator\",\n",
    "                         values=\"Value\",\n",
    "                         aggfunc=\"first\")\n",
    "            .reset_index())\n",
    "\n",
    "pivot_df.columns.name = None  # flatten\n",
    "\n",
    "# Save processed merged CSV\n",
    "proc_merged_path = os.path.join(MERGED_PROC_DIR,\n",
    "                                \"energy_indicators_merged_pivot.csv\")\n",
    "pivot_df.to_csv(proc_merged_path, index=False)\n",
    "\n",
    "# ── 4. INDIVIDUAL INDICATOR FILES ───────────────────────────\n",
    "for ind, grp in df.groupby(\"Indicator\"):\n",
    "    slug = slugify(ind)\n",
    "    raw_dir  = os.path.join(IND_ROOT, slug, \"raw\")\n",
    "    proc_dir = os.path.join(IND_ROOT, slug, \"processed\")\n",
    "    os.makedirs(raw_dir,  exist_ok=True)\n",
    "    os.makedirs(proc_dir, exist_ok=True)\n",
    "    # purge previous runs\n",
    "    for p in glob.glob(os.path.join(raw_dir, \"*\")):  os.remove(p)\n",
    "    for p in glob.glob(os.path.join(proc_dir, \"*\")): os.remove(p)\n",
    "\n",
    "    grp.to_csv(os.path.join(raw_dir, f\"{slug}_raw.csv\"), index=False)\n",
    "\n",
    "    tidy = (long_df[long_df[\"Indicator\"] == ind]\n",
    "            .drop(columns=\"Indicator\"))           # Economy, Year, Value\n",
    "    tidy.to_csv(os.path.join(proc_dir, f\"{slug}_clean.csv\"), index=False)\n",
    "\n",
    "# ── 5. SHOW SAMPLE ──────────────────────────────────────────\n",
    "print(\"\\nSample of merged Energy dataset (columns:\", len(pivot_df.columns), \")\")\n",
    "print(pivot_df.head())\n",
    "# -------------------------------------------------------------\n",
    "#  Google Colab single‑cell script   (ADB › Energy indicators)\n",
    "# -------------------------------------------------------------\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import os, re, glob, io, tempfile, zipfile, requests, pandas as pd\n",
    "\n",
    "# ── CONFIG ───────────────────────────────────────────────────\n",
    "URL  = \"https://kidb.adb.org/explore/download/4e61528b-8aec-4c49-951c-b36641766eeb\"\n",
    "ROOT = \"/content/drive/MyDrive/ADB/Global/Energy\"\n",
    "\n",
    "MERGED_RAW_DIR  = os.path.join(ROOT, \"Merged_Indicators\", \"raw\")\n",
    "MERGED_PROC_DIR = os.path.join(ROOT, \"Merged_Indicators\", \"processed\")\n",
    "IND_ROOT        = os.path.join(ROOT, \"Individual_Indicators\")\n",
    "\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR, IND_ROOT):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Wipe previous merged files so each run keeps only the latest pull\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR):\n",
    "    for f in glob.glob(os.path.join(d, \"*\")):\n",
    "        try: os.remove(f)\n",
    "        except: pass\n",
    "\n",
    "def slugify(txt: str) -> str:\n",
    "    return re.sub(r'[^\\w\\s-]', '', txt).strip().replace(\" \", \"_\")\n",
    "\n",
    "# ── 1. DOWNLOAD  ─────────────────────────────────────────────\n",
    "resp = requests.get(URL, timeout=60)\n",
    "resp.raise_for_status()\n",
    "content = resp.content\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    if content[:2] == b\"PK\":                               # ZIP archive\n",
    "        zpath = os.path.join(tmp, \"data.zip\"); open(zpath, \"wb\").write(content)\n",
    "        with zipfile.ZipFile(zpath) as z:\n",
    "            member = next(m for m in z.namelist() if m.lower().endswith((\".csv\", \".xlsx\")))\n",
    "            raw_bytes = z.read(member)\n",
    "            ext = os.path.splitext(member)[1].lower()\n",
    "    else:                                                  # single file\n",
    "        raw_bytes = content\n",
    "        ext = \".csv\" if b\",\" in content.splitlines()[0] else \".xlsx\"\n",
    "\n",
    "raw_merged_path = os.path.join(MERGED_RAW_DIR, f\"energy_indicators_raw{ext}\")\n",
    "open(raw_merged_path, \"wb\").write(raw_bytes)\n",
    "\n",
    "# ── 2. LOAD RAW DATAFRAME ───────────────────────────────────\n",
    "read_fn = pd.read_csv if ext == \".csv\" else pd.read_excel\n",
    "df = read_fn(io.BytesIO(raw_bytes))\n",
    "\n",
    "df.columns = [c.strip().replace(\"\\n\", \" \") for c in df.columns]\n",
    "assert {\"Indicator\", \"Economy\"}.issubset(df.columns), \"Columns 'Indicator' & 'Economy' required!\"\n",
    "\n",
    "# ── 3. LONG → WIDE MERGED TABLE (Economy, Year, indicators) ─\n",
    "year_cols = [c for c in df.columns if re.fullmatch(r\"\\d{4}\", str(c))]\n",
    "long_df = (df.melt(id_vars=[\"Indicator\", \"Economy\"],\n",
    "                   value_vars=year_cols,\n",
    "                   var_name=\"Year\",\n",
    "                   value_name=\"Value\")\n",
    "           .dropna(subset=[\"Value\"]))\n",
    "\n",
    "pivot_df = (long_df\n",
    "            .pivot_table(index=[\"Economy\", \"Year\"],\n",
    "                         columns=\"Indicator\",\n",
    "                         values=\"Value\",\n",
    "                         aggfunc=\"first\")\n",
    "            .reset_index())\n",
    "\n",
    "pivot_df.columns.name = None  # flatten\n",
    "\n",
    "# Save processed merged CSV\n",
    "proc_merged_path = os.path.join(MERGED_PROC_DIR,\n",
    "                                \"energy_indicators_merged_pivot.csv\")\n",
    "pivot_df.to_csv(proc_merged_path, index=False)\n",
    "\n",
    "# ── 4. INDIVIDUAL INDICATOR FILES ───────────────────────────\n",
    "for ind, grp in df.groupby(\"Indicator\"):\n",
    "    slug = slugify(ind)\n",
    "    raw_dir  = os.path.join(IND_ROOT, slug, \"raw\")\n",
    "    proc_dir = os.path.join(IND_ROOT, slug, \"processed\")\n",
    "    os.makedirs(raw_dir,  exist_ok=True)\n",
    "    os.makedirs(proc_dir, exist_ok=True)\n",
    "    # purge previous runs\n",
    "    for p in glob.glob(os.path.join(raw_dir, \"*\")):  os.remove(p)\n",
    "    for p in glob.glob(os.path.join(proc_dir, \"*\")): os.remove(p)\n",
    "\n",
    "    grp.to_csv(os.path.join(raw_dir, f\"{slug}_raw.csv\"), index=False)\n",
    "\n",
    "    tidy = (long_df[long_df[\"Indicator\"] == ind]\n",
    "            .drop(columns=\"Indicator\"))           # Economy, Year, Value\n",
    "    tidy.to_csv(os.path.join(proc_dir, f\"{slug}_clean.csv\"), index=False)\n",
    "\n",
    "# ── 5. SHOW SAMPLE ──────────────────────────────────────────\n",
    "print(\"\\nSample of merged Energy dataset (columns:\", len(pivot_df.columns), \")\")\n",
    "print(pivot_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M396AkGrPkIy"
   },
   "source": [
    "Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-16T05:16:34.807021Z",
     "iopub.status.busy": "2025-05-16T05:16:34.806730Z",
     "iopub.status.idle": "2025-05-16T05:18:42.736107Z",
     "shell.execute_reply": "2025-05-16T05:18:42.735130Z"
    },
    "executionInfo": {
     "elapsed": 9157,
     "status": "ok",
     "timestamp": 1747216948177,
     "user": {
      "displayName": "Aayush",
      "userId": "06063773002916323156"
     },
     "user_tz": -330
    },
    "id": "wJyIjauDPmWJ",
    "outputId": "fbff87f5-5143-40d5-ad74-c953c92acddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of merged Demographics dataset (columns: 13 )\n",
      "     Economy  Year Age Dependency Ratio Gini Coefficient  \\\n",
      "0  Australia  2015          51.06329837              ...   \n",
      "1  Australia  2016          51.60344566      0.336858104   \n",
      "2  Australia  2017          52.04242094              ...   \n",
      "3  Australia  2018           52.4455123      0.343337622   \n",
      "4  Australia  2019          52.91976024              ...   \n",
      "\n",
      "  Growth Rates in Population Human Development Index  \\\n",
      "0                1.428871347                   0.933   \n",
      "1                1.549756313                   0.936   \n",
      "2                1.633418183                   0.937   \n",
      "3                1.484979951                   0.941   \n",
      "4                1.466362474                   0.941   \n",
      "\n",
      "  Income Ratio of Highest 20% to Lowest 20%  \\\n",
      "0                                       ...   \n",
      "1                               5.554054054   \n",
      "2                                       ...   \n",
      "3                               5.726027397   \n",
      "4                                       ...   \n",
      "\n",
      "  Net International Migration Rate (per 1,000 population) Population density  \\\n",
      "0                                              8.867                 3.09795   \n",
      "1                                             10.466                 3.14194   \n",
      "2                                             10.312                     3.2   \n",
      "3                                              9.013                     3.3   \n",
      "4                                              8.129                     3.3   \n",
      "\n",
      "  Proportion of Population Living on Less Than $2.15 a Day (2017 PPP) (%)  \\\n",
      "0                                                ...                        \n",
      "1                                                ...                        \n",
      "2                                                ...                        \n",
      "3                                                ...                        \n",
      "4                                                ...                        \n",
      "\n",
      "  Proportion of Population Living on Less Than $3.65 a Day (2017 PPP) (%)  \\\n",
      "0                                                ...                        \n",
      "1                                                ...                        \n",
      "2                                                ...                        \n",
      "3                                                ...                        \n",
      "4                                                ...                        \n",
      "\n",
      "  Total population Urban population (% of total population)  \n",
      "0         23816000                              86.80056407  \n",
      "1         24190900                              86.95107215  \n",
      "2         24592600                              87.07592304  \n",
      "3         24963300                              87.17651358  \n",
      "4         25334800                              87.26906986  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "#  Google Colab single‑cell script   (ADB › Demographics)\n",
    "# -------------------------------------------------------------\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import os, re, glob, io, tempfile, zipfile, requests, pandas as pd\n",
    "\n",
    "# ── CONFIG ───────────────────────────────────────────────────\n",
    "URL  = \"https://kidb.adb.org/explore/download/415c4ae7-64e4-489d-abc3-1797a2febc46\"\n",
    "ROOT = \"/content/drive/MyDrive/ADB/Global/Demographics\"\n",
    "\n",
    "MERGED_RAW_DIR  = os.path.join(ROOT, \"Merged_Indicators\", \"raw\")\n",
    "MERGED_PROC_DIR = os.path.join(ROOT, \"Merged_Indicators\", \"processed\")\n",
    "IND_ROOT        = os.path.join(ROOT, \"Individual_Indicators\")\n",
    "\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR, IND_ROOT):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# wipe previous merged files so each run keeps only the latest pull\n",
    "for d in (MERGED_RAW_DIR, MERGED_PROC_DIR):\n",
    "    for f in glob.glob(os.path.join(d, \"*\")):\n",
    "        try: os.remove(f)\n",
    "        except: pass\n",
    "\n",
    "def slugify(txt: str) -> str:\n",
    "    return re.sub(r'[^\\w\\s-]', '', txt).strip().replace(\" \", \"_\")\n",
    "\n",
    "# ── 1. DOWNLOAD DATASET ─────────────────────────────────────\n",
    "resp = requests.get(URL, timeout=60)\n",
    "resp.raise_for_status()\n",
    "content = resp.content\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    if content[:2] == b\"PK\":                               # ZIP archive\n",
    "        zpath = os.path.join(tmp, \"data.zip\")\n",
    "        open(zpath, \"wb\").write(content)\n",
    "        with zipfile.ZipFile(zpath) as z:\n",
    "            member = next(m for m in z.namelist()\n",
    "                           if m.lower().endswith((\".csv\", \".xlsx\")))\n",
    "            raw_bytes = z.read(member)\n",
    "            ext = os.path.splitext(member)[1].lower()\n",
    "    else:                                                  # single file\n",
    "        raw_bytes = content\n",
    "        ext = \".csv\" if b\",\" in content.splitlines()[0] else \".xlsx\"\n",
    "\n",
    "raw_merged_path = os.path.join(MERGED_RAW_DIR,\n",
    "                               f\"demographics_indicators_raw{ext}\")\n",
    "open(raw_merged_path, \"wb\").write(raw_bytes)\n",
    "\n",
    "# ── 2. LOAD RAW DATAFRAME ───────────────────────────────────\n",
    "read_fn = pd.read_csv if ext == \".csv\" else pd.read_excel\n",
    "df = read_fn(io.BytesIO(raw_bytes))\n",
    "\n",
    "df.columns = [c.strip().replace(\"\\n\", \" \") for c in df.columns]\n",
    "assert {\"Indicator\", \"Economy\"}.issubset(df.columns), \\\n",
    "    \"Columns 'Indicator' & 'Economy' required!\"\n",
    "\n",
    "# ── 3. PIVOT TO MERGED TABLE  (Economy · Year · indicators) ─\n",
    "year_cols = [c for c in df.columns if re.fullmatch(r\"\\d{4}\", str(c))]\n",
    "long_df = (df.melt(id_vars=[\"Indicator\", \"Economy\"],\n",
    "                   value_vars=year_cols,\n",
    "                   var_name=\"Year\",\n",
    "                   value_name=\"Value\")\n",
    "           .dropna(subset=[\"Value\"]))\n",
    "\n",
    "pivot_df = (long_df\n",
    "            .pivot_table(index=[\"Economy\", \"Year\"],\n",
    "                         columns=\"Indicator\",\n",
    "                         values=\"Value\",\n",
    "                         aggfunc=\"first\")\n",
    "            .reset_index())\n",
    "\n",
    "pivot_df.columns.name = None  # flatten the header\n",
    "\n",
    "proc_merged_path = os.path.join(\n",
    "    MERGED_PROC_DIR, \"demographics_indicators_merged_pivot.csv\"\n",
    ")\n",
    "pivot_df.to_csv(proc_merged_path, index=False)\n",
    "\n",
    "# ── 4. SPLIT INTO INDIVIDUAL INDICATOR FOLDERS ─────────────\n",
    "for ind_name, grp in df.groupby(\"Indicator\"):\n",
    "    slug = slugify(ind_name)\n",
    "    raw_dir  = os.path.join(IND_ROOT, slug, \"raw\")\n",
    "    proc_dir = os.path.join(IND_ROOT, slug, \"processed\")\n",
    "    os.makedirs(raw_dir,  exist_ok=True)\n",
    "    os.makedirs(proc_dir, exist_ok=True)\n",
    "\n",
    "    # clear previous run\n",
    "    for p in glob.glob(os.path.join(raw_dir, \"*\")):  os.remove(p)\n",
    "    for p in glob.glob(os.path.join(proc_dir, \"*\")): os.remove(p)\n",
    "\n",
    "    # wide raw file (all year columns)\n",
    "    grp.to_csv(os.path.join(raw_dir, f\"{slug}_raw.csv\"), index=False)\n",
    "\n",
    "    # tidy clean file: Economy, Year, Value\n",
    "    tidy = (long_df[long_df[\"Indicator\"] == ind_name]\n",
    "            .drop(columns=\"Indicator\"))\n",
    "    tidy.to_csv(os.path.join(proc_dir, f\"{slug}_clean.csv\"), index=False)\n",
    "\n",
    "# ── 5. SHOW SAMPLE ──────────────────────────────────────────\n",
    "print(\"\\nSample of merged Demographics dataset (columns:\", len(pivot_df.columns), \")\")\n",
    "print(pivot_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPaC7JVTxmex4OWcglkKOM8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
